{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Spark Cluster Performance\n",
    "The purpose of this notebook is to demonstrate the advantages of a Spark cluster query as opposed to a Postgres database query. It is best to complete the entire notebook in one sitting, as opposed to leaving it and coming\n",
    "back later. If you choose to leave it and come back to it later, you most likely experience glitches in the server.\n",
    "It is also important to run each of these top to bottom, and WAIT until one cell is finished before starting the next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating the SQL context from the spark context, which is the entry point into the relational functionality of\n",
    "# our spark cluster. \n",
    "# Importing libraries. We need the time library to use the time.time() function.\n",
    "\n",
    "import time\n",
    "from pyspark import SQLContext, SparkContext, SparkConf\n",
    "sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates the DataFrame from the SQLContext created above.  The DataFrame is based on the contents of our JSON file. \n",
    "\n",
    "This file contains the content from the **Amazon Product Reviews Dataset**. DataFrames allow us to manipulate and interact with structured data via a domain-specific language. Our domain-specific language is Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This creates the DataFrame from the SQLContext based on the contents of our JSON file. This file contains the\n",
    "# content from the reviews database. DataFrames allow us to manipulate and interact with structured data via a\n",
    "# domain-specific language. Our domain-specific language is Python. \n",
    "\n",
    "df = sqlContext.read.json(\"In/reviews.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This prints the schema. \n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is a basic query that selects twenty scores (a.k.a. ratings) of different movies and TV shows. The 'twenty'\n",
    "# is a constraint on the system to prevent the accidental retrieval of about thirty-four million rows. \n",
    "# This query does not specify how many to return.\n",
    "\n",
    "df2 = df.select(\"score\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can register a DataFrame as a table for the purpose of running an SQL query on the dataset. \n",
    "\n",
    "sqlContext.registerDataFrameAsTable(df, \"reviews\")\n",
    "df3 = sqlContext.sql(\"SELECT productId, price from reviews limit 5\")\n",
    "df3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we will run a more time-consuming query since our dataset is gigantic. (When I ran this, it took almost \n",
    "# five minutes, and my internet connection is fairly good.)\n",
    "\n",
    "start = time.time()\n",
    "df4 = sqlContext.sql(\"SELECT COUNT(DISTINCT title) FROM reviews\")\n",
    "df4.collect()\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You should see a large difference between this time and the runtime of the postgres query. (Mine was about half\n",
    "# the time of the postgres query.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python"
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
