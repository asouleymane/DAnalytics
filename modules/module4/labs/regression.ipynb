{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Module 4 - Lab 1: Building a Regression Model with Spark\n",
    "\n",
    "This lab will build upon the previous lab. \n",
    "While classification models deal with outcomes that represent discrete classes, regression models are concerned with target variables that can take any real value. Our goal is to find a model that maps input features to predicted target variables. \n",
    "Like classification, regression is also a form of supervised learning.\n",
    "\n",
    "We can use regression models to predict a mulititude of different variables of interest. \n",
    "Here are some examples of how this technique is used in society:\n",
    "* Predicting stock returns and other economic variables\n",
    "* Predicting loss amounts for loan defaults (this can be combined with a classification model that predicts the probability of default, while the regression model predicts the amount in the case of a default)\n",
    "* Predicting customer lifetime value (CLTV) in a retail, mobile, or other business, based on user behavior and spending patterns\n",
    "\n",
    "Below, we will fire up our Spark cluster and prepare it for data visualization like we have done in previous labs. See Module 3 - Lab 1: Feature-Extraction-MoreContext for a detailed description of what is happening below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.mllib.regression import LinearRegressionWithSGD\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "\n",
    "# Make Random String\n",
    "import os, random, string\n",
    "length = 32\n",
    "chars = string.ascii_letters + string.digits + '_-'\n",
    "random.seed = (os.urandom(1024))\n",
    "\n",
    "rndfolder = ''.join(random.choice(chars) for i in range(length))\n",
    "dirpath = '/home/hadoop/work_dir/' + rndfolder + '/'\n",
    "\n",
    "# Set Path and permissions (\"0770\", which means everyone can read and write the file)\n",
    "os.mkdir(dirpath, 0770)\n",
    "os.chdir(dirpath)\n",
    "\n",
    "def process_figure(fig, name):\n",
    "    fig.savefig(name)\n",
    "    print 'http://ec2-54-153-99-19.us-west-1.compute.amazonaws.com:8810/' + rndfolder + '/' + name\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('agg') # non-graphical mode (pngs(?))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of regression models\n",
    "Let's talk about the different types of regression models before we dive into coding up an example.\n",
    "Spark's MLlib library offers two broad classes of regression models: linear models and decision tree regression models.\n",
    "Linear regression models use a different loss function, related link function, and decision function than its classification counterparts.\n",
    "(We will go over these functions in minute.)\n",
    "MLlib provides a standard least squares regression model, which is a type of a linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least square regression\n",
    "There is a variety of loss functions that can be applied to generalized linear models. \n",
    "(A loss function is a function that maps an event (or values of one or more variables) onto a real number intuitively representing some \"cost\" associated with the event.)\n",
    "\n",
    "This is the loss function used for least squares (a.k.a. the squared loss):\n",
    "    1/2[(w^T) * x - y]^2\n",
    "* y: the target variable (it has a real value)\n",
    "* w: weight vector\n",
    "* x: feature vector\n",
    "* T: instance? \n",
    "\n",
    "So what is this useful for? \n",
    "What does all of this actually mean?\n",
    "Least Squares Regression is the method for summarizing a pattern in a dataset that suggests a linear relationship.\n",
    "This allows us to predict an outcome, y, for a given input, x. \n",
    "(i.e. We can describe (or predict) how a response variable, y, changes as an explanatory variable, x, changes.)\n",
    "This model is useful for SPECIFIC situations.\n",
    "The standard least squares regression in MLlib does not use regularization (which is a process of introducing additional information in order to solve an ill-posed problem or to prevent overfitting).\n",
    "We can see that the loss applied to incorrectly predicted points will be magnified since the loss is squared.\n",
    "This means that least squares regression is susceptible to outliers in the dataset and also to over-fitting.\n",
    "So, generally, we should apply some level of regularization to account for this.\n",
    "\n",
    "Here are some things that may happen using this technique against the data (so if you aren't sure what the data looks like and you use this method, the following situations could occur):\n",
    "* A curved pattern might appear showing that the relationship is not linear\n",
    "* Increasing or decreasing spread about the line as x increases indicates that prediction of y will be LESS accurate for larger x's.\n",
    "* Individual points with large residuals are outliers  in the vertical direction\n",
    "* Individual points that are extreme in the x direction are also important....as influential observations\n",
    "This link is helpful for explaining this concept even further: http://www.henry.k12.ga.us/ugh/apstat/chapternotes/sec3.3.html\n",
    "(I recommend reading it. It's not too long, and I think it is helpful to explain the math behind the method.)\n",
    "\n",
    "The link function is the identity link.\n",
    "The decision function is also the identity function, since generally, no thresholding is applied in regression. \n",
    "Therefore, the model's prediction is simply: y = (w^T) * x\n",
    "\n",
    "Linear regression with L2 regularization is commonly referred to as ridge regression, while applying L1 regularization is called the lasso.\n",
    "To understand this concept better, read the \"Regularization\" section of this website: http://www.chioka.in/differences-between-l1-and-l2-as-loss-function-and-regularization/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees for regression\n",
    "The Decision tree method builds regression or classification models in the form of a tree structure. \n",
    "It brakes down a dataset into smaller and smaller subsets while incrementally developing an associated decision tree at the same time.\n",
    "The final result is a tree with decision nodes and leaf nodes.\n",
    "\n",
    "* A decision node has two or more branches each representing values for the attribute being tested.\n",
    "* A leaf node represents a decision on the numerical target. \n",
    "* The topmost node is called the \"root node\".\n",
    "\n",
    "Decision trees can handle both categorical and numerical data.\n",
    "A decision tree is built top-down from a root node and involves partitioning the data into subsets that contain instances with similar values (homogenous).\n",
    "We use standard deviation to calculate the homogeneity of a numerical sample.\n",
    "If the numerical sample is completely homogeneous its standard deviation is zero.\n",
    "The standard deviation reduction is based on the decrease in standard deviation after a dataset is split on an attribute. \n",
    "Constructing a decision tree is all about finding attribute that returns the highest standard deviation reduction (i.e., the most homogeneous branches).\n",
    "I recommend reading this content for a more detailed explanation of this concept: \n",
    "http://chem-eng.utoronto.ca/~datamining/dmc/decision_tree_reg.htm\n",
    "\n",
    "Just like using linear models for regression tasks involves changing the loss function used, using decision trees for regression involves changing the measure of the node impurity used.\n",
    "The impurity metric is called variance and is defined in the same way as the squared loss for least squares linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the right features from you data\n",
    "As the underlying models for regression are the same as those for the classification case, we can use the same approach to create input features. \n",
    "The only practical difference is that the target is now a real-valued variable, as opposed to a categorical one. \n",
    "The `LabeledPoint` class in MLlib already takes this into account, as the label field is of the `Double` type, so it can handle both cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features from the bike sharing dataset\n",
    "To illustrate the concepts in this chapter, we will be using the bike sharing dataset. \n",
    "This dataset contains hourly records of the number of bicycle rentals in the capital bike sharing system. \n",
    "It also contains variables related to date and time, weather, and seasonal and holiday information.\n",
    "\n",
    "Here are the variable names and descriptions:\n",
    "\n",
    "* `instant`: This is the record ID\n",
    "* `dteday`: This is the raw data\n",
    "* `season`: This is different seasons such as spring, summer, winter, and fall\n",
    "* `yr`: This is the year (2011 or 2012)\n",
    "* `mnth`: This is the month of the year\n",
    "* `hr`: This is the hour of the day\n",
    "* `holiday`: This is whether the day was a holiday or not\n",
    "* `weekday`: This is the day of the week\n",
    "* `workingday`: This is whether the day was a working day or not\n",
    "* `weathersit`: This is a categorical variable that describes the weather at a particular time\n",
    "* `temp`: This is the normalized temperature\n",
    "* `atemp`: This is the normalized apparent temperature\n",
    "* `hum`: This is the normalized humidity\n",
    "* `windspeed`: This is the normalized wind speed\n",
    "* `cnt`: This is the target variable, that is, the count of bike rentals for that hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"bike/hour_noheader.csv\"\n",
    "raw_data = sc.textFile(path)\n",
    "num_data = raw_data.count()\n",
    "records = raw_data.map(lambda x: x.split(\",\"))\n",
    "first = records.first()\n",
    "print first\n",
    "print num_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code above loads the \"bike/hour_noheader.csv\" dataset into the Spark instance that is created (similar to previous datasets that we have used in earlier modules).\n",
    "The data is then counted in the line `num_data = raw_data.count()`. \n",
    "The data is then parsed in this line `records = raw_data.map(lambda x: x.split(\",\"))`. \n",
    "\n",
    "* The lambda expression splits each line in the data set by the comma (,) character and returns the list to be stored in the `records` variable.\n",
    "\n",
    "The first line in the records dataset is selected in this line `first = records.first()`.\n",
    "It is then printed and along with the number of records that was previously counted. \n",
    "As we can see from the results, we have 17,379 hourly records in our dataset. \n",
    "For now, we will ignore the record ID and raw date columns.\n",
    "We will also ignore the `casual` and `registered` count target variables and focus on the overall count variable, `cnt` (which is the sum of the other two counts).\n",
    "We are left with 12 variables. \n",
    "The first eight are categorical, while the last 4 are normalized real-valued variables.\n",
    "\n",
    "To deal with the eight categorical variables, we will use the binary encoding approach.\n",
    "The four real-valued variables will be left as is.\n",
    "\n",
    "First, we will cache the dataset since we will be reading from it a lot in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "records.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to extract each categorical feature into a binary vector form, we will need to know the feature mapping of each feature value to the index of the nonzero value in our binary vector.\n",
    "So this means....what?\n",
    "\n",
    "* We need to use a binary vector to store the codes for the eight categorical variabes the we get from our binary encoding method. (We haven't done this yet.)\n",
    "* To perform this method, we have to know how each feature maps to an index within the binary vector. \n",
    "\n",
    "Let's define a function that will extract this mapping from our dataset for a given column.\n",
    "The function below will do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mapping(rdd, idx):\n",
    "    return rdd.map(lambda fields: fields[idx]).distinct().zipWithIndex().collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `get_mapping(rdd, idx)` first maps the field to its unique values. \n",
    "Then, it uses the `zipWithIndex()` transformation to \"zip\" the value up with a unique index such that a key-value RDD is formed.\n",
    "In the formulated RDD, the key is the variable and the value is the index.\n",
    "\n",
    "* This index will be the index of the nonzero entry in the binary vector representation of the feature.\n",
    "\n",
    "We then collect this RDD back to the driver as a Python dictionary via the `collectAsMap()` function.\n",
    "\n",
    "Let's test our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Mapping of first categorical feature column: %s\" % get_mapping(records, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's apply the function to each categorical column (i.e. for variable indices 2 to 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mappings = [get_mapping(records, i) for i in range(2,10)]\n",
    "cat_len = sum(map(len, mappings))\n",
    "num_len = len(records.first()[11:15])\n",
    "total_len = num_len + cat_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the mappings for each variable (as seen in the code above), and we can see how many values in total we need for our binary vector representation in the code below.\n",
    "\n",
    "In the code block above:\n",
    "\n",
    "* `mappings = [get_mapping(records, i) for i in range(2,10)]` obtains the mappings that we desire for each variable.\n",
    "* `cat_len = sum(map(len, mappings))` obtains the length of each variable's mapping, and then sums them.\n",
    "* `num_len = len(records.first()[11:15])` obtains the length of the values in the 11th-15th indices in the first list in records\n",
    "    * `first()` gets the first item from the `records` list\n",
    "* `total_len = num_len + cat_len` calculates the total length of the values, which will be necessary for our tree construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print \"Feature vector length for categorical features: %d\" % cat_len\n",
    "print \"Feature vector length for numerical features: %d\" % num_len\n",
    "print \"Total feature vector length: %d\" % total_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating feature vectors for linear model\n",
    "The next step is to use our extracted mappings to convert the categorical features to binary-encoded features. \n",
    "Again, it will be helpful to create a function that we can apply to each record in our dataset for this purpose. \n",
    "We will also create a function to extract the target variable from each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(record):\n",
    "    cat_vec = np.zeros(cat_len)\n",
    "    i = 0\n",
    "    step = 0\n",
    "    for field in record[2:9]:\n",
    "        m = mappings[i]\n",
    "        idx = m[field]\n",
    "        cat_vec[idx + step] = 1\n",
    "        i = i + 1\n",
    "        step = step + len(m)\n",
    "    num_vec = np.array([float(field) for field in record[10:14]])\n",
    "    return np.concatenate((cat_vec, num_vec))\n",
    "def extract_label(record):\n",
    "    return float(record[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the function `extract_features(record)`, we ran through each column in the row of data via the `for` loop.\n",
    "Before the `for` loop, we created a vector of zeros in the line `cat_vec = np.zeros(cat_len)`.\n",
    "We extracted the binary encoding for each variable in turn from the mappings we created previously via the line `m = mappings[i]`.\n",
    "We then assign the binary encoding to the `idx` variable in line `idx = m[field]`. \n",
    "In the line `cat_vec[idx + step] = 1` we encode a `1` at the location `idx + step` in the `cat_vec` vector.\n",
    "We increment the value of `i` to move forward in the mappings vector. \n",
    "The `step` variable ensures that the nonzero feature index in the full feature vector (a.k.a. `cat_vec`) is correct (and is somewhat more efficient than, say, creating many smaller binary vectors and concatenating them).\n",
    "The numeric vector (`num_vec`) is created directly by first converting the data to floating point numbers and wrapping these in a numpy array. \n",
    "The resulting two vectors are then concatenated and returned.\n",
    "\n",
    "The `extract_label` function simply converts the last column variable (the count) into a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = records.map(lambda r: LabeledPoint(extract_label(r), extract_features(r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we extract labels and feature vectors from our records data using the `extract_label()` and `extract_features()` functions.\n",
    "The `LabeldPoint(label, feature)` function takes in a label (denoted `label`) and a feature (denoted `feature`), which is a vector of features for this point.\n",
    "The class `LabeledPoint` represents the features and labels of a data point.\n",
    "\n",
    "Let's now inspect the first record in the extracted feature RDD (a.k.a. the `data` RDD that we created above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_point = data.first()\n",
    "print \"Raw data: \" + str(first[2:])\n",
    "print \"Label: \" + str(first_point.label)\n",
    "print \"Linear Model feature vector:\\n\" + str(first_point.features)\n",
    "print \"Linear Model feature vector length: \" + str(len(first_point.features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we converted the raw data into a feature vector made up of the binary categorical and real numeric features, and we indeed have a total vector length of 61.\n",
    "\n",
    "So what does this tell us?\n",
    "The Linear Model feature vector shown above shows the binary encoding for each categorical feature that was present before in the raw data. \n",
    "We will now move on, so that we can use this feature vector in more useful ways.\n",
    "(Obviously, just looking at the values of a giant vector is not as useful as looking at a visual representation or doing performance metrics on the vector itself.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating feature vectors for the decision tree\n",
    "Now, we will create a separate function to extract the decision tree feature vector, which simply converts all the values to floats and wraps them in a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_features_dt(record):\n",
    "    return np.array(map(float, record[2:14]))\n",
    "data_dt = records.map(lambda r: LabeledPoint(extract_label(r), extract_features_dt(r)))\n",
    "first_point_dt = data_dt.first()\n",
    "print \"Decision Tree feature vector: \" + str(first_point_dt.features)\n",
    "print \"Decision Tree feature vector length: \" + str(len(first_point_dt.features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and using regression models\n",
    "Training for regression models using decision trees and linear models follows the same procedure as for classi cation models. We simply pass the training data contained in a [LabeledPoint] RDD to the relevant `train` method. \n",
    "In Python, we are provided with a convenience method that gives us access to all the available model arguments, so we only have to use this one entry point for training. \n",
    "We can see the details of these convenience functions by calling the `help()` function on the `train` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(LinearRegressionWithSGD.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(DecisionTree.trainRegressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a regression model on the bike sharing dataset\n",
    "We're ready to use the features we have extracted to train our models on the bike sharing data. \n",
    "First, we'll train the linear regression model and take a look at the first few predictions that the model makes on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear_model = LinearRegressionWithSGD.train(data, iterations=10, step=0.1, intercept=False)\n",
    "true_vs_predicted = data.map(lambda p: (p.label, linear_model.predict(p.features)))\n",
    "print \"Linear Model predictions: \" + str(true_vs_predicted.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code block does the following:\n",
    "\n",
    "`linear_model = LinearRegressionWithSGD.train(data, iterations=10, step=0.1, intercept=False)`\n",
    "\n",
    "* The function `LinearRegressionWithSGD.train()` provides our linear model. (The details can be read above.)\n",
    "\n",
    "`true_vs_predicted = data.map(lambda p: (p.label, linear_model.predict(p.features)))`\n",
    "\n",
    "* Here, we obtain the \"label\", which is the value we expect from the data, and the prediction (what we expect based on our model).\n",
    "\n",
    "Note that we have not used the default settings for `iterations` and `step` here. \n",
    "We've changed the number of iterations so that the model does not take too long to train.\n",
    "With more iterations, we get a better model - one that can better predict output when given a set of intput.\n",
    "However, it also takes more time to train the model. \n",
    "\n",
    "Next, we will train the decision tree model simply using the default arguments to the `trainRegressor` method (which equates to using a tree depth of 5). \n",
    "Note that we need to pass in the other form of the dataset, `data_dt`, that we created from the raw feature values (as opposed to the binary encoded features that we used for the preceding linear model).\n",
    "\n",
    "We also need to pass in an argument for `categoricalFeaturesInfo`. \n",
    "This is a dictionary that maps the categorical feature index to the number of categories for the feature. \n",
    "If a feature is not in this mapping, it will be treated as continuous. \n",
    "For our purposes, we will leave this as is, passing in an empty mapping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_model = DecisionTree.trainRegressor(data_dt,{})\n",
    "preds = dt_model.predict(data_dt.map(lambda p: p.features))\n",
    "actual = data.map(lambda p: p.label)\n",
    "true_vs_predicted_dt = actual.zip(preds)\n",
    "print \"Decision Tree predictions: \" + str(true_vs_predicted_dt.take(5))\n",
    "print \"Decision Tree depth: \" + str(dt_model.depth())\n",
    "print \"Decision Tree number of nodes: \" + str(dt_model.numNodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After observing the output of both of these methods, it appears that the decision tree may do better. \n",
    "(The linear modeal is WAY off in all of its predictions.)\n",
    "However, we will perform more stringent evaluation methods to find out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating performance\n",
    "When dealing with regression models, it is very unlikely that our model will precisely predict the target variable, because the target variable can take on any real value. \n",
    "However, we would naturally like to understand how far away our predicted values are from the true values, so will we utilize a metric that takes into account the overall deviation.\n",
    "\n",
    "Some of the standard evaluation metrics used to measure the performance of regression models include the Mean Squared Error (MSE) and Root Mean Squared Error (RMSE), the Mean Absolute Error (MAE), the R-squared coefficient, and many others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error and Root Mean Squared Error\n",
    "MSE is the average of the squared error that is used as the loss function for least squares regression:\n",
    "\n",
    "I will attempt to write the equation here, but no guarantees it will look nice.. \n",
    "\n",
    "Summation from i = 1 to n of [ (w^T * x(i) - y(i))^2 / n ]\n",
    "\n",
    "It is the sum, over all the data points, of the square of the difference between the predicted and actual target variables, divided by the number of data points.\n",
    "(Target variables are our predicted values.)\n",
    "\n",
    "RMSE is the square root of MSE. \n",
    "MSE is measured in units that are the square of the target variable, while RMSE is measured in the same units as the target variable. \n",
    "Due to its formulation, MSE, just like the squared loss function that it derives from, effectively penalizes larger errors more severely.\n",
    "\n",
    "In order to evaluate our predictions based on the mean of an error metric, we will first make predictions for each input feature vector in an RDD of `LabeledPoint` instances by computing the error for each record using a function that takes the prediction and true target value as inputs. \n",
    "This will return a [`Double`] RDD (in other words, an RDD that contains items of type `Double`) that contains the error values. \n",
    "We can then find the average using the `mean` method of RDDs that contain `Double` values.\n",
    "\n",
    "Below, we define our squared error function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def squared_error(actual, pred):\n",
    "    return (pred - actual)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function takes in two variables, `actual` and `pred`, which represent the actual value and the predicted value, respectively. \n",
    "It then returns the the squared difference between `pred` and `actual`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Error\n",
    "MAE is the average of the absolute differences between the predicted and actual targets:\n",
    "\n",
    "Again, I will attempt to describe the equation..\n",
    "\n",
    "Summation from i = 1 to n of [ | w^T * x(i) - y(i) | / n ]\n",
    "\n",
    "MAE is similar in principle to MSE, but it does not punish large deviations as much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abs_error(actual, pred):\n",
    "    return np.abs(pred - actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Mean Squared Log Error\n",
    "This measurement is not as widely used as MSE and MAE, but it is used as the metric for the Kaggle competition that uses the bike sharing dataset. \n",
    "It is effectively the RMSE of the log-transformed predicted and target values. \n",
    "This measurement is useful when there is a wide range in the target variable, and you do not necessarily want to penalize large errors when the predicted and target values are themselves high. \n",
    "It is also effective when you care about percentage errors rather than the absolute value of errors.\n",
    "\n",
    "Below is the function to compute the RMSLE. \n",
    "CHALLENGE: See if you can write the mathematical equation! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squared_log_error(pred, actual):\n",
    "    return (np.log(pred + 1) - np.log(actual + 1))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The R-squared coefficient\n",
    "Here, we will briefly talk about the R-squared coefficients.\n",
    "\n",
    "The R-squared coefficient, also known as the coefficient of determination, is a measure of how well a model fits a dataset. \n",
    "It is commonly used in statistics. \n",
    "It measures the degree of variation in the target variable (our predicted variable); this is explained by the variation in the input features. \n",
    "An R-squared coefficient generally takes a value between 0 and 1, where 1 equates to a perfect  fit of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing performance metrics on the bike sharing dataset\n",
    "Given the functions we de ned earlier, we can now compute the various evaluation metrics on our bike sharing data.\n",
    "\n",
    "## Linear model\n",
    "Our approach will be to apply the relevant error function to each record in the RDD we computed earlier, which is `true_vs_predicted` for our linear model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse = true_vs_predicted.map(lambda (t, p): squared_error(t, p)).mean()\n",
    "mae = true_vs_predicted.map(lambda (t, p): abs_error(t, p)).mean()\n",
    "rmsle = np.sqrt(true_vs_predicted.map(lambda (t, p): squared_log_error(t, p)).mean())\n",
    "print \"Linear Model - Mean Squared Error: %2.4f\" % mse\n",
    "print \"Linear Model - Mean Absolute Error: %2.4f\" % mae\n",
    "print \"Linear Model - Root Mean Squared Log Error: %2.4f\" % rmsle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code block above:\n",
    "\n",
    "* We calculate the squared error of each tuple in the `true_vs_predicted` variable, and then we calculate the mean of that dictionary, which gives us the mean squared error.\n",
    "* We then calculate the mean average error by calculating the absolute error on every tuple in the `true_vs_predicted` variable and then, taking the mean of that that dictionary.\n",
    "* We then calculate the root mean squared log error. To do this, we have to take the mean of the dictionary created from applying the `squared_log_error` function to each tuple in the `true_vs_predicted` dictionary.\n",
    "\n",
    "We then print the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree\n",
    "We will use the same approach for the decision tree model, using the `true_vs_ predicted_dt` RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse_dt = true_vs_predicted_dt.map(lambda (t, p): squared_error(t, p)).mean()\n",
    "mae_dt = true_vs_predicted_dt.map(lambda (t, p): abs_error(t, p)).mean()\n",
    "rmsle_dt = np.sqrt(true_vs_predicted_dt.map(lambda (t, p): squared_log_error(t, p)).mean())\n",
    "print \"Decision Tree - Mean Squared Error: %2.4f\" % mse_dt\n",
    "print \"Decision Tree - Mean Absolute Error: %2.4f\" % mae_dt\n",
    "print \"Decision Tree - Root Mean Squared Log Error: %2.4f\" % rmsle_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results, we can see that our initial guess about the decision tree model being the better performer is indeed true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving model performance and tuning parameters\n",
    "It is true that feature transformation and selection can make a large difference to the performance of a model.\n",
    "Here, we will focus on another type of transformation that can be applied to a dataset: transforming the target variable itself.\n",
    "We will do this in a variety of ways and plot histograms to observe the changes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the target variable\n",
    "Recall that many machine learning models, including linear models, make assumptions regarding the distribution of the input data as well as target variables. \n",
    "In particular, linear regression assumes a normal distribution.\n",
    "\n",
    "In many real-world cases, the distributional assumptions of linear regression do not hold. \n",
    "In this case, for example, we know that the number of bike rentals can never be negative. \n",
    "This alone should indicate that the assumption of normality might be problematic. \n",
    "To get a better idea of the target distribution, it is often a good idea to plot a histogram of the target values.\n",
    "\n",
    "We will now create a plot of the target variable distribution in the following piece of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "targets = records.map(lambda r: float(r[-1])).collect()\n",
    "plt.hist(targets, bins=40, color='lightblue', normed=True)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(16, 10)\n",
    "process_figure(fig, 'target_distribution.png')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the histogram plot, we can see that the distribution is highly skewed and certainly does not follow a normal distribution.\n",
    "\n",
    "One way in which we might deal with this situation is by applying a transformation to the target variable, such that we take the logarithm of the target value instead of the raw value.\n",
    "This is often referred to as log-transforming the target variable (this transformation can also be applied to feature values).\n",
    "\n",
    "We will apply a log transformation to the following target variable and plot a histogram of the log-transformed values in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_targets = records.map(lambda r: np.log(float(r[-1]))).collect()\n",
    "plt.hist(log_targets, bins=40, color='lightblue', normed=True)\n",
    "fig = plt.gcf()\n",
    "process_figure(fig, 'log_target.png')\n",
    "fig.set_size_inches(16, 10)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that the data is more normally distributed. Notice that it is now skewed the other direction.\n",
    "\n",
    "A second type of transformation that is useful in the case of target values that do not take on negative values and, in addition, might take on a very wide range of values, is to take the square root of the variable.\n",
    "\n",
    "We will apply the square root transform in the following code, once more plotting the resulting target variable distribution in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqrt_targets = records.map(lambda r: np.sqrt(float(r[-1]))).collect()\n",
    "plt.hist(sqrt_targets, bins=40, color='lightblue', normed=True)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(16, 10)\n",
    "process_figure(fig, 'sqrt_target.png')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots of the log and square root transformations, we can see that both\n",
    "result in a more even distribution relative to the raw values. \n",
    "While they are still not normally distributed, they are a lot closer to a normal distribution when compared to the original target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of training\n",
    "So, does applying these transformations have any impact on model performance? \n",
    "Let's evaluate the various metrics we used previously on log-transformed data as an example.\n",
    "We will do this first for the linear model by applying the numpy `log` function to the `label` field of each `LabeledPoint` RDD. \n",
    "Here, we will only transform the target variable, and we will not apply any transformations to the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_log = data.map(lambda lp: LabeledPoint(np.log(lp.label), lp.features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then train a model on this transformed data and form the RDD of predicted versus true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_log = LinearRegressionWithSGD.train(data_log, iterations=10, step=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that now that we have transformed the target variable, the predictions of the model will be on the log scale, as will the target values of the transformed dataset. \n",
    "Therefore, in order to use our model and evaluate its performance, we must first transform the log data back into the original scale by taking the exponent of both the predicted and true values using the `numpy exp` function. \n",
    "We will do this in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_vs_predicted_log = data_log.map(lambda p: (np.exp(p.label), np.exp(model_log.predict(p.features))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our model is transformed back to its original state, we can calculate the MSE, MAE, and the RMSLE metrics for this model.\n",
    "This is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse_log = true_vs_predicted_log.map(lambda (t, p): squared_error(t, p)).mean()\n",
    "mae_log = true_vs_predicted_log.map(lambda (t, p): abs_error(t, p)).mean()\n",
    "rmsle_log = np.sqrt(true_vs_predicted_log.map(lambda (t, p): squared_log_error(t, p)).mean())\n",
    "print \"Mean Squared Error: %2.4f\" % mse_log\n",
    "print \"Mean Absolue Error: %2.4f\" % mae_log\n",
    "print \"Root Mean Squared Log Error: %2.4f\" % rmsle_log\n",
    "print \"Non log-transformed predictions:\\n\" + str(true_vs_predicted.take(3))\n",
    "print \"Log-transformed predictions:\\n\" + str(true_vs_predicted_log.take(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare these results to the results on the raw target variable, we see that while we did not improve the MSE or MAE, we improved the RMSLE.\n",
    "\n",
    "We will perform the same analysis for the decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dt_log = data_dt.map(lambda lp: LabeledPoint(np.log(lp.label), lp.features))\n",
    "dt_model_log = DecisionTree.trainRegressor(data_dt_log,{})\n",
    "preds_log = dt_model_log.predict(data_dt_log.map(lambda p: p.features))\n",
    "actual_log = data_dt_log.map(lambda p: p.label)\n",
    "true_vs_predicted_dt_log = actual_log.zip(preds_log).map(lambda (t, p): (np.exp(t), np.exp(p)))\n",
    "mse_log_dt = true_vs_predicted_dt_log.map(lambda (t, p): squared_error(t, p)).mean()\n",
    "mae_log_dt = true_vs_predicted_dt_log.map(lambda (t, p): abs_error(t, p)).mean()\n",
    "rmsle_log_dt = np.sqrt(true_vs_predicted_dt_log.map(lambda (t, p): squared_log_error(t, p)).mean())\n",
    "print \"Mean Squared Error: %2.4f\" % mse_log_dt\n",
    "print \"Mean Absolue Error: %2.4f\" % mae_log_dt\n",
    "print \"Root Mean Squared Log Error: %2.4f\" % rmsle_log_dt\n",
    "print \"Non log-transformed predictions:\\n\" + str(true_vs_predicted_dt.take(3))\n",
    "print \"Log-transformed predictions:\\n\" + str(true_vs_predicted_dt_log.take(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these results, we can see that we actually made our metrics slightly worse for the decision tree.\n",
    "\n",
    "It is probably not surprising that the log transformation results in a better RMSLE performance for the linear model. \n",
    "As we are minimizing the squared error, once we have transformed the target variable to log values, we are effectively minimizing a loss function that is very similar to the RMSLE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning\n",
    "So far, we have illustrated the concepts of model training and evaluation for MLlib's regression models by training and testing on the same dataset.\n",
    "We will now use a similar cross-validation approach that we used previously to evaluate the effect on performance of different parameter settings for our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating training and testing sets to evaluate parameters\n",
    "The first step is to create a test and training set for cross-validation purposes.\n",
    "We will need to create a training and test dataset manually, since Spark's Python API does not yet provide the methods available in other languages.\n",
    "\n",
    "One relatively easy way to do this is by first taking a random sample of, say, twenty percent of our data as our test set. \n",
    "We will then define our training set as the elements of the original RDD that are not in the test set RDD.\n",
    "\n",
    "We can achieve this using the sample method to take a random sample for our test set, followed by using the `subtractByKey method`, which takes care of returning the elements in one RDD where the keys do not overlap with the other RDD.\n",
    "\n",
    "Note that `subtractByKey`, as the name suggests, works on the keys of the RDD elements that consist of key-value pairs. \n",
    "Therefore, here we will use `zipWithIndex` on our RDD of extracted training examples. This creates an RDD of (`LabeledPoint`, `index`) pairs.\n",
    "\n",
    "We will then reverse the keys and values so that we can operate on the index keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_with_idx = data.zipWithIndex().map(lambda (k, v): (v, k))\n",
    "test = data_with_idx.sample(False, 0.2, 42)\n",
    "train = data_with_idx.subtractByKey(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the two RDDs, we will recover just the `LabeledPoint` instances we need for training and test data, using map to extract the value from the key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = train.map(lambda (idx, p): p)\n",
    "test_data = test.map(lambda (idx, p) : p)\n",
    "train_size = train_data.count()\n",
    "test_size = test_data.count()\n",
    "print \"Training data size: %d\" % train_size\n",
    "print \"Test data size: %d\" % test_size\n",
    "print \"Total data size: %d \" % num_data\n",
    "print \"Train + Test size : %d\" % (train_size + test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to apply the same approach to the features extracted for the decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_with_idx_dt = data_dt.zipWithIndex().map(lambda (k, v): (v, k))\n",
    "test_dt = data_with_idx_dt.sample(False, 0.2, 42)\n",
    "train_dt = data_with_idx_dt.subtractByKey(test_dt)\n",
    "train_data_dt = train_dt.map(lambda (idx, p): p)\n",
    "test_data_dt = test_dt.map(lambda (idx, p) : p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The impact of parameter settings for linear models\n",
    "Now that we have prepared our training and test sets, we are ready to investigate the impact of different parameter settings on model performance. \n",
    "We will first carry out this evaluation for the linear model. \n",
    "We will create a convenience function to evaluate the relevant performance metric by training the model on the training set and evaluating it on the test set for different parameter settings.\n",
    "\n",
    "We will use the RMSLE evaluation metric.\n",
    "The evaluation function is defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(train, test, iterations, step, regParam, regType, intercept):\n",
    "    model = LinearRegressionWithSGD.train(train, iterations, step,\n",
    "                                          regParam=regParam, regType=regType, intercept=intercept)\n",
    "    tp = test.map(lambda p: (p.label, model.predict(p.features)))\n",
    "    rmsle = np.sqrt(tp.map(lambda (t, p): squared_log_error(t, p)).mean())\n",
    "    return rmsle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the following sections, you might get slightly different results due to some random initialization for SGD. \n",
    "However, your results will be comparable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterations\n",
    "We generally expect that a model trained with SGD will achieve better performance as the number of iterations increases, although the increase in performance will slow down as the number of iterations goes above some minimum number. \n",
    "Note that here, we will set the step size to 0.01 to better illustrate the impact at higher iteration numbers.\n",
    "\n",
    "The output shows that the error metric indeed decreases as the number of iterations increases.\n",
    "It also does so at a decreasing rate, again as expected. \n",
    "What is interesting is that eventually, the SGD optimization tends to overshoot the optimal solution, and the RMSLE eventually starts to increase slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = [1, 5, 10, 20, 50, 100]\n",
    "metrics = [evaluate(train_data, test_data, param, 0.01, 0.0, 'l2', False) for param in params]\n",
    "print params\n",
    "print metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will use the `matplotlib` library to plot a graph of the RMSLE metric against the number of iterations. \n",
    "We will use a log scale for the x axis to make the output easier to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(params, metrics)\n",
    "fig = plt.gcf()\n",
    "plt.xscale('log')\n",
    "process_figure(fig, 'iteration_stats.png')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step size\n",
    "We will perform a similar analysis for step size in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = [0.01, 0.025, 0.05, 0.1, 1.0]\n",
    "metrics = [evaluate(train_data, test_data, 10, param, 0.0, 'l2', False) for param in params]\n",
    "print params\n",
    "print metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see why we avoided using the default step size when training the linear model originally. \n",
    "The default is set to 1.0, which, in this case, results in a nan output for the RMSLE metric.\n",
    "This typically means that the SGD model has converged to a very poor local minimum in the error function that it is optimizing. \n",
    "This can happen when the step size is relatively large, as it is easier for the optimization algorithm to overshoot good solutions.\n",
    "\n",
    "We can also see that for low step sizes and a relatively low number of iterations (we used ten here), the model performance is slightly poorer. \n",
    "However, in the preceding **Iterations** section, we saw that for the lower step-size setting, a higher number of iterations will generally converge to a better solution.\n",
    "\n",
    "Generally speaking, setting step size and number of iterations involves a trade-off. \n",
    "A lower step size means that convergence is slower but slightly more assured. \n",
    "However, it requires a higher number of iterations, which is more costly in terms of computation and time, in particular at a very large scale.\n",
    "\n",
    "**NOTE**: Selecting the best parameter settings can be an intensive process that involves training a model on many combinations of parameter settings and selecting the best outcome.\n",
    "Each instance of model training involves a number of iterations, so this process can be very expensive and time consuming when performed on very large datasets.\n",
    "\n",
    "Below, we plot the output, again, using a log scale for the step-size axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(params, metrics)\n",
    "fig = plt.gcf()\n",
    "plt.xscale('log')\n",
    "process_figure(fig, 'step_stats.png')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 regularization\n",
    "Regularization has the effect of penalizing model complexity in the form of an additional loss term that is a function of the model weight vector. \n",
    "L2 regularization penalizes the L2-norm of the weight vector, while L1 regularization penalizes the L1-norm.\n",
    "\n",
    "We expect training set performance to deteriorate with increasing regularization, as the model cannot fit the dataset well. \n",
    "However, we would also expect some amount of regularization that will result in optimal generalization performance as evidenced by the best performance on the test set.\n",
    "\n",
    "Below, we will evaluate the impact of different levels of L2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = [0.0, 0.01, 0.1, 1.0, 5.0, 10.0, 20.0]\n",
    "metrics = [evaluate(train_data, test_data, 10, 0.1, param, 'l2', False) for param in params]\n",
    "print params\n",
    "print metrics\n",
    "plt.plot(params, metrics)\n",
    "fig = plt.gcf()\n",
    "plt.xscale('log')\n",
    "process_figure(fig, 'l2_stats.png')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there is an optimal setting of the regularization parameter with respect to the test set RMSLE.\n",
    "This is easiest to see in the above plot (where we once more use the log scale for the regularization parameter axis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 Regularization\n",
    "We can apply the same approach for differing levels of L1 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = [0.0, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "metrics = [evaluate(train_data, test_data, 10, 0.1, param, 'l1', False) for param in params]\n",
    "print params\n",
    "print metrics\n",
    "plt.plot(params, metrics)\n",
    "fig = plt.gcf()\n",
    "plt.xscale('log')\n",
    "process_figure(fig, 'l1_stats.png')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the results are more clearly seen when plotted in the following graph. \n",
    "We see that there is a much more subtle decline in RMSLE, and it takes a very high value to cause a jump back up. \n",
    "Here, the level of L1 regularization required is much higher than that for the L2 form; however, the overall performance is poorer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using L1 regularization can encourage sparse weight vectors. \n",
    "Does this hold true in this case? \n",
    "We can find out by examining the number of entries in the weight vector that are zero, with increasing levels of regularization.\n",
    "\n",
    "We can see from the results that as we might expect, the number of zero feature weights in the model weight vector increases as greater levels of L1 regularization are applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_l1 = LinearRegressionWithSGD.train(train_data, 10, 0.1, regParam=1.0, regType='l1', intercept=False)\n",
    "model_l1_10 = LinearRegressionWithSGD.train(train_data, 10, 0.1, regParam=10.0, regType='l1', intercept=False)\n",
    "model_l1_100 = LinearRegressionWithSGD.train(train_data, 10, 0.1, regParam=100.0, regType='l1', intercept=False)\n",
    "print \"L1 (1.0) number of zero weights: \" + str(sum(model_l1.weights.array == 0))\n",
    "print \"L1 (10.0) number of zeros weights: \" + str(sum(model_l1_10.weights.array == 0))\n",
    "print \"L1 (100.0) number of zeros weights: \" + str(sum(model_l1_100.weights.array == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intercept\n",
    "The final parameter option for the linear model is whether to use an intercept or not. \n",
    "An intercept is a constant term that is added to the weight vector and effectively accounts for the mean value of the target variable. \n",
    "If the data is already centered or normalized, an intercept is not necessary; however, it often does not hurt to use one in any case.\n",
    "Below, we will evaluate the effect of adding an intercept term to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = [False, True]\n",
    "metrics = [evaluate(train_data, test_data, 10, 0.1, 1.0, 'l2', param) for param in params]\n",
    "print params\n",
    "print metrics\n",
    "plt.bar(params, metrics, color='lightblue')\n",
    "fig = plt.gcf()\n",
    "process_figure(fig, 'intercept_stats.png')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the results that as we might expect, the number of zero feature weights in the model weight vector increases as greater levels of L1 regularization are applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The impact of parameter settings for the decision tree\n",
    "Decision trees provide two main parameters: maximum tree depth and the maximum number of bins.\n",
    "We will now perform the same evaluation of the effect of parameter settings for the decision tree model. \n",
    "Our starting point is to create an evaluation function for the model, similar to the one used for the linear regression earlier. \n",
    "This function is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_dt(train, test, maxDepth, maxBins):\n",
    "    model = DecisionTree.trainRegressor(train, {}, impurity='variance', maxDepth=maxDepth, maxBins=maxBins)\n",
    "    preds = model.predict(test.map(lambda p: p.features))\n",
    "    actual = test.map(lambda p: p.label)\n",
    "    tp = actual.zip(preds)\n",
    "    rmsle = np.sqrt(tp.map(lambda (t, p): squared_log_error(t, p)).mean())\n",
    "    return rmsle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Depth\n",
    "We would generally expect performance to increase with more complex trees (that is, trees of greater depth). \n",
    "Having a lower tree depth acts as a form of regularization, and it might be the case that as with L2 or L1 regularization in linear models, there is a tree depth that is optimal with respect to the test set performance.\n",
    "\n",
    "Here, we will try to increase the depths of trees to see what impact they have on test set RMSLE, keeping the number of bins at the default level of thirty-two.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = [1, 2, 3, 4, 5, 10, 20]\n",
    "metrics = [evaluate_dt(train_data_dt, test_data_dt, param, 32) for param in params]\n",
    "print params\n",
    "print metrics\n",
    "plt.plot(params, metrics)\n",
    "fig = plt.gcf()\n",
    "process_figure(fig, 'tree_depth_stats.png')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, it appears that the decision tree starts over-fitting at deeper tree levels. \n",
    "An optimal tree depth appears to be around ten on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Bins\n",
    "Finally, we will perform our evaluation on the impact of setting the number of bins for the decision tree. \n",
    "As with the tree depth, a larger number of bins should allow the model to become more complex and might help performance with larger feature dimensions. \n",
    "After a certain point, it is unlikely that it will help any more and might, in fact, hinder performance on the test set due to over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = [2, 4, 8, 16, 32, 64, 100]\n",
    "metrics = [evaluate_dt(train_data_dt, test_data_dt, 5, param) for param in params]\n",
    "print params\n",
    "print metrics\n",
    "plt.plot(params, metrics)\n",
    "fig = plt.gcf()\n",
    "process_figure(fig, 'bin_stats.png')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will show the output and plot to vary the number of bins (while keeping the tree depth at the default level of five). \n",
    "In this case, using a small number of bins hurts performance, while there is no impact when we use around thirty-two bins (the default setting) or more. \n",
    "There seems to be an optimal setting for test set performance at around 16-20 bins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this chapter, you saw how to use MLlib's linear model and decision tree functionality in Python within the context of regression models. \n",
    "We explored categorical feature extraction and the impact of applying transformations to the target variable in a regression problem. \n",
    "Finally, we implemented various performance-evaluation metrics and used them to implement a cross-validation exercise that explores the impact of the various parameter settings available in both linear models and decision trees on test set model performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python"
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
