{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2:  Data Pipelines\n",
    "## Topics Covered\n",
    "* Feature Extraction\n",
    "* Recommendation Systems\n",
    "* Data Pipelines\n",
    "    \n",
    "## Readings\n",
    " - [What Do Emoji's Mean](./readings/ICWSM2016_emoji.pdf) Data pipelines are increasingly including emoji information, which is ripe for misinterpretation. This is a thought provoking article along those lines. \n",
    " - [Introduction to Spark with Python](http://www.kdnuggets.com/2015/11/introduction-spark-python.html) This will feel heavy and techy. KDNuggets is like that. Do not worry about reading this for mastery right now. Instead, focus on getting a zoomed out sense of some of the things that Spark can do, and how it is useful. The short answer, which you will see in one of the videos, is that it allows the load of processing data to be distributed across a **cluster**. \n",
    "\n",
    " \n",
    "## Reference Information\n",
    " - [PySpark References](http://spark.apache.org/docs/latest/api/python/)\n",
    " - [PySpark Worked Examples](https://vanishingcodes.wordpress.com/2016/06/09/pyspark-tutorial-building-a-random-forest-binary-classifier-on-unbalanced-dataset/)\n",
    " \n",
    "## Labs\n",
    "Labs are focused in this module on the development of data pipelines in Spark, using Spark based machine learning algorithms. \n",
    " - [Feature Extraction in Spark](./labs/1-Feature-Extraction.ipynb)\n",
    " - [Recommendation Engines (Collaborative Filtering) in Spark](./labs/2-Recommendation-Engines.ipynb)\n",
    " \n",
    "## Practice Examples\n",
    " - Forthcoming\n",
    " \n",
    "## Exercises\n",
    " - Forthcoming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python"
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
